{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunohdmacedo/ML-FOR-DETECTION-OF-EXOPLANETS/blob/main/Local_Updated_Classic_Algorithms_ML_Exoplanets_Curves.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzCi_V0fpryt"
      },
      "outputs": [],
      "source": [
        "!pip install catboost\n",
        "!pip install xlsxwriter\n",
        "!pip install catboost\n",
        "!pip install scikit-optimize\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuPWAmm0nKKi"
      },
      "outputs": [],
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score, accuracy_score,precision_score, average_precision_score, make_scorer, f1_score,recall_score,roc_auc_score,balanced_accuracy_score\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import *\n",
        "from threading import Thread\n",
        "from openpyxl import load_workbook\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import os\n",
        "import xlsxwriter\n",
        "from pathlib import Path\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTcWaZe8L3ed"
      },
      "source": [
        "#Experimento dados shallue Local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2bw91gZMGZV"
      },
      "outputs": [],
      "source": [
        "# Caminho do arquivo de dados\n",
        "data_path = 'shallue_all_local.csv'\n",
        "data = pd.read_csv(data_path, sep = \",\")\n",
        "\n",
        "# Definição do input e label no formato tabular exigido pelo scikit-learn\n",
        "data_input = data.copy()\n",
        "label = data_input.pop(data_input.columns[len(data_input.columns)-1])\n",
        "X = data_input.values #tamanho limitado para testes rápidos\n",
        "y = label.values #tamanho limitado para testes rápidos\n",
        "\n",
        "#normalização\n",
        "norm_data = data_input.copy()\n",
        "norm_data = norm_data.apply(lambda x: (x-x.min())/(x.max()-x.min()), axis=1)\n",
        "X_ = norm_data.values #tamanho limitado para testes rápidos\n",
        "\n",
        "#label binário\n",
        "lb = LabelBinarizer()\n",
        "y = lb.fit_transform(label)\n",
        "y = y.reshape(-1) #tamanho limitado para testes rápidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFPs_mz8X0w_"
      },
      "outputs": [],
      "source": [
        "def experiment(model_name, model, params, X_, y, book_name='Local', pos_label=1):\n",
        "    # Caminho da pasta para salvar o arquivo\n",
        "    data_path = 'Classicos/Local'\n",
        "  \n",
        "    # Nome do arquivo para salvar os resultados\n",
        "    results_file = os.path.join(data_path, model_name+ \"_\" + book_name + '.xlsx')\n",
        "\n",
        "    # configure the cross-validation procedure\n",
        "    cv_outer = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, (train_ix, test_ix) in enumerate(cv_outer.split(X_, y)):\n",
        "        # split data\n",
        "        X_train, X_test = X_[train_ix, :], X_[test_ix, :]\n",
        "        y_train, y_test = y[train_ix], y[test_ix]\n",
        "\n",
        "        # configure the cross-validation procedure\n",
        "        cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
        "\n",
        "        # define search\n",
        "        search = BayesSearchCV(model, params, scoring='accuracy', cv=cv_inner, n_iter=10, refit=True, random_state=1, n_jobs=1)\n",
        "\n",
        "        # execute search\n",
        "        result = search.fit(X_train, y_train)\n",
        "\n",
        "        # get the best performing model fit on the whole training set\n",
        "        best_model = result.best_estimator_\n",
        "\n",
        "        # evaluate model on the hold out dataset\n",
        "        yhat = best_model.predict(X_test)\n",
        "\n",
        "        # evaluate the model\n",
        "        acc = accuracy_score(y_test, yhat)\n",
        "        prec = precision_score(y_test, yhat, pos_label=pos_label, average='macro', zero_division=1)\n",
        "        rec = recall_score(y_test, yhat, pos_label=pos_label)\n",
        "        f1 = f1_score(y_test, yhat, pos_label=pos_label)\n",
        "\n",
        "        # store the result\n",
        "        results.append([model_name, i, acc, rec, prec, f1, result.best_score_, result.best_params_])\n",
        "\n",
        "        # report progress\n",
        "        #print(f\"{model_name} {i} > acc={acc:.3f}, est={result.best_score_:.3f}, cfg={result.best_params_}\")\n",
        "        f = open('saida.txt', 'a')\n",
        "        f.write(f\"{model_name} {i} > acc={acc:.3f}, est={result.best_score_:.3f}, cfg={result.best_params_}\\n\")\n",
        "        f.close()\n",
        "\n",
        "    # summarize the estimated performance of the model\n",
        "    mean_acc = sum(r[2] for r in results) / len(results)\n",
        "    mean_rec = sum(r[3] for r in results) / len(results)\n",
        "    mean_prec = sum(r[4] for r in results) / len(results)\n",
        "    mean_f1 = sum(r[5] for r in results) / len(results)\n",
        "\n",
        "    # save results to file\n",
        "    df = pd.DataFrame(results, columns=['model', 'run', 'acc', 'rec', 'prec', 'f1', 'best_score', 'best_params'])\n",
        "    df.to_excel(results_file, index=False)\n",
        "\n",
        "    return {'model': model_name, 'mean_acc': mean_acc, 'mean_rec': mean_rec, 'mean_prec': mean_prec, 'mean_f1': mean_f1}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2vIPEzvTIN0"
      },
      "outputs": [],
      "source": [
        "# definição dos modelos e parametros\n",
        "model_params = {\n",
        "          'lr': {'model': LogisticRegression(),\n",
        "                'params': {\n",
        "                            'C': Real(1e-4, 1e4, prior='log-uniform'),\n",
        "                            'fit_intercept': Categorical([True, False]),\n",
        "                            'solver': Categorical(['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
        "                            'max_iter':[500],\n",
        "                            'random_state': [1]}},\n",
        "\n",
        "          'knn': {'model': KNeighborsClassifier(),\n",
        "                  'params': {\n",
        "                            'n_neighbors': Integer(1, 50),\n",
        "                            'weights': Categorical(['uniform', 'distance']),\n",
        "                            'algorithm': Categorical(['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
        "                            'p': Integer(1, 5)}},\n",
        "\n",
        "          'nb': {'model': GaussianNB(),\n",
        "                'params': {\n",
        "                         'var_smoothing': Real(1e-10, 1e-1, prior='log-uniform')}},\n",
        "\n",
        "          'dt': {'model': DecisionTreeClassifier(),\n",
        "                'params': {\n",
        "                            'criterion': Categorical(['gini', 'entropy']),\n",
        "                            'splitter': Categorical(['best', 'random']),\n",
        "                            'max_depth': Integer(3, 30),\n",
        "                            'min_samples_split': Integer(2, 10),\n",
        "                            'min_samples_leaf': Integer(1, 10),\n",
        "                            'max_features': Real(0.1, 1.0, prior='uniform'),\n",
        "                            'random_state': [1]}},\n",
        "\n",
        "          'svm': {'model': SVC(),\n",
        "                  'params': {\n",
        "                            'C': Real(2**-5, 2**5, prior='log-uniform'),\n",
        "                            'kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n",
        "                            'degree': Integer(2, 5),  # Somente relevante para o kernel 'poly'\n",
        "                            'coef0': Real(0, 1),      # Relevante para os kernels 'poly' e 'sigmoid'\n",
        "                            'gamma': Real(2**-9, 2**1, prior='log-uniform'),\n",
        "                            'random_state': [1]}},\n",
        "\n",
        "          'gpc': {'model': GaussianProcessClassifier(),\n",
        "                  'params': {\n",
        "                            'optimizer': Categorical(['fmin_l_bfgs_b', None]),\n",
        "                            'n_restarts_optimizer': Integer(0, 10),\n",
        "                            'max_iter_predict': [500],\n",
        "                            'random_state': [1]}},\n",
        "\n",
        "          'mlp': {'model': MLPClassifier(),\n",
        "                  'params': {\n",
        "                            'hidden_layer_sizes': Integer(10,100),\n",
        "                            'activation': Categorical(['logistic', 'tanh', 'relu']),\n",
        "                            'solver': Categorical(['sgd', 'adam']),\n",
        "                            'max_iter': [5000],\n",
        "                            'random_state': [1]}},\n",
        "\n",
        "          'ridge': {'model': RidgeClassifier(),\n",
        "                    'params': {\n",
        "                                'alpha': Real(1e-4, 1e4, prior='log-uniform'),\n",
        "                                'fit_intercept': Categorical([True, False]),\n",
        "                                'solver': Categorical(['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']),\n",
        "                                'random_state': [1]}},\n",
        "\n",
        "          'rf': {'model': RandomForestClassifier(),\n",
        "                'params': {\n",
        "                          'n_estimators': Integer(10, 500),\n",
        "                          'criterion': Categorical(['gini', 'entropy']),\n",
        "                         'max_depth': Integer(3, 30),\n",
        "                          'random_state': [1]}},\n",
        "\n",
        "          'qda': {'model': QuadraticDiscriminantAnalysis(),\n",
        "                  'params': {\n",
        "                            'reg_param': Real(0, 1, prior='uniform'),\n",
        "                            'store_covariance': Categorical([True, False]),\n",
        "                            'tol': Real(1e-5, 1e-1, prior='log-uniform')}},\n",
        "\n",
        "          'ada': {'model': AdaBoostClassifier(),\n",
        "                  'params': {\n",
        "                            'n_estimators': Integer(10, 500),\n",
        "                            'learning_rate': Real(1e-3, 1, prior='log-uniform'),\n",
        "                           'algorithm': Categorical(['SAMME', 'SAMME.R']),\n",
        "                           'random_state': [1]}},\n",
        "\n",
        "          'gbc': {'model': GradientBoostingClassifier(),\n",
        "                  'params': {    \n",
        "                            'n_estimators': Integer(10, 500),\n",
        "                            'learning_rate': Real(1e-3, 1, prior='log-uniform'),\n",
        "                            'max_depth': Integer(3, 10),\n",
        "                            'random_state': [1]}},\n",
        "\n",
        "          'lda': {'model': LinearDiscriminantAnalysis(),\n",
        "                 'params': {\n",
        "                           'solver': Categorical(['svd', 'lsqr', 'eigen']),\n",
        "                           'shrinkage': Real(0, 1, prior='uniform'),\n",
        "                           'tol': Real(1e-6, 1e-4, prior='log-uniform')}},\n",
        "\n",
        "          'et': {'model': ExtraTreesClassifier(),\n",
        "                 'params': {\n",
        "                         'n_estimators': Integer(10, 500),\n",
        "                         'criterion': Categorical(['gini', 'entropy']),\n",
        "                         'max_depth': Integer(3, 30)}},\n",
        "\n",
        "          'xgboost': {'model': XGBClassifier(),\n",
        "                      'params': {\n",
        "                                'learning_rate': Real(0.01, 0.3, prior='uniform'),\n",
        "                                'n_estimators': Integer(50, 500),\n",
        "                                'max_depth': Integer(3, 10),\n",
        "                                'gamma': Real(0, 1, prior='uniform'),\n",
        "                                }},\n",
        "                \n",
        "          'lightgbm': {'model': LGBMClassifier(),\n",
        "                      'params': {\n",
        "                                'learning_rate': Real(1e-3, 1, prior='log-uniform'),\n",
        "                                'n_estimators': Integer(10, 500),\n",
        "                                'num_leaves': Integer(2, 100),\n",
        "                                'max_depth': Integer(3, 10)}}\n",
        "\n",
        "          'catboost': {'model': CatBoostClassifier(verbose=0),\n",
        "                     'params': {\n",
        "                               'learning_rate': Real(1e-3, 1, prior='log-uniform'),\n",
        "                               'iterations': Integer(10, 500),\n",
        "                               'depth': Integer(3, 10),\n",
        "                               'l2_leaf_reg': Real(1, 10, prior='uniform'),\n",
        "                               'border_count': Integer(1, 255),\n",
        "                               'bagging_temperature': Real(0, 1, prior='uniform'),\n",
        "                               'random_strength': Real(1e-9, 10, prior='log-uniform')}}\n",
        "                   \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIPAbU4_UyZn",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "#threads = []\n",
        "\n",
        "#inicia uma thread para cada algoritmo de ML\n",
        "#os experimentos para cada algoritmo serão executados de forma concorrente\n",
        "#for model_name, mp in model_params.items():\n",
        "#  exp = Thread(target=experiment,args=[model_name, mp['model'],mp['params'], X_, y])\n",
        "#  exp.start() #inicia thread\n",
        "#  threads.append(exp) #adiciona na lista para salvar a referencia da thread\n",
        "\n",
        "#for i in range (len(threads)):\n",
        "#  threads[i].join() #retoma o resultado para o programa chamador\n",
        "\n",
        "for model_name, mp in model_params.items():\n",
        "  experiment(model_name, mp['model'],mp['params'], X_, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrMKZ5EXq_HT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bPsvEkxGMlDS",
        "RTcWaZe8L3ed"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}